# Set of models with accuracy issues, because of PA
EleutherAI/pythia-160m
bigscience/bloomz-1b7
bigscience/bloomz-560m
databricks/dolly-v2-3b
tiiuae/falcon-rw-7b
bigcode/starcoder2-3b
openbmb/MiniCPM-2B-sft-bf16
openbmb/MiniCPM-2B-dpo-bf16
Qwen/Qwen-7B
Qwen/Qwen-7B-Chat
Qwen/Qwen1.5-0.5B
Qwen/Qwen1.5-7B-Chat
rinna/bilingual-gpt-neox-4b
google/pegasus-big_patent
google/pegasus-large
#
# Set of models, which require support in optimum-intel:
internlm/internlm-chat-7b
BAAI/Aquila-7B
internlm/internlm2-7b
Salesforce/codegen2-1b
Salesforce/xgen-7b-8k-base
facebook/blenderbot-3B
#
# Set of models, failed because of CPU limitation
# CPU: head size must be multiple of 16, current: 100: pankajmathur/orca_mini_3b
# CPU: head size must be multiple of 16, current: 100: openlm-research/open_llama_3b
# CPU: head size must be multiple of 16, current: 100: openlm-research/open_llama_3b_v2
#
# Set of failed models, because of PA:
BAAI/AquilaChat2-7B
BAAI/AquilaChat-7B
baichuan-inc/Baichuan-7B
tiiuae/falcon-7b
microsoft/Phi-3-mini-128k-instruct
microsoft/Phi-3-mini-4k-instruct
bigcode/starcoderbase-3b
bigcode/gpt_bigcode-santacoder
nomic-ai/gpt4all-mpt
mosaicml/mpt-7b
facebook/opt-350m
#
# Set of models, failed because of OpenVINO Tokenizers:
# RuntimeError: Check 'rt_info.find("eos_token_id") != rt_info.end(): facebook/incoder-1B
#
# Set of 13B, 30B abd 70B models:
EleutherAI/gpt-neox-20b
# big model, not tried: core42/jais-13b
core42/jais-13b-chat
# big model, not tried: young-geng/koala
mistralai/Mixtral-8x7B-v0.1
# big model, not tried: mistralai/Mixtral-8x7B-Instruct-v0.1
# big model, not tried: mosaicml/mpt-30b
OrionStarAI/Orion-14B-Base
# big model, not tried: OrionStarAI/Orion-14B-Chat
# big model, not tried: Qwen/Qwen1.5-MoE-A2.7B
Qwen/Qwen1.5-MoE-A2.7B-Chat
# big model, not tried: xverse/XVERSE-MoE-A4.2B
#
# Set of passed models:
microsoft/phi-2
microsoft/phi-1_5
EleutherAI/gpt-neo-125m
EleutherAI/gpt-neo-125m
EleutherAI/gpt-neo-1.3B
EleutherAI/gpt-j-6b
baichuan-inc/Baichuan2-7B-Chat
THUDM/chatglm2-6b
THUDM/chatglm3-6b
google/gemma-2b
google/gemma-7b
openai-community/gpt2
openai-community/gpt2-xl
gpt2
gpt2-xl
nomic-ai/gpt4all-j
stabilityai/stablelm-3b-4e1t
stabilityai/stablelm-2-zephyr-1_6b
meta-llama/Llama-2-7b-hf
meta-llama/Meta-Llama-3-8B-Instruct
meta-llama/CodeLlama-7b-hf
lmsys/vicuna-7b-v1.3
mistralai/Mistral-7B-v0.1
mistralai/Mistral-7B-Instruct-v0.1
allenai/OLMo-1B-hf
allenai/OLMo-7B-hf
01-ai/Yi-6B
Salesforce/codegen-350M-multi
Salesforce/codegen-350M-nl
togethercomputer/RedPajama-INCITE-Chat-3B-v1
# passed, but with export=False: OpenVINO/codegen25-7b-multi-fp16-ov
#
# Set of invalid models, because of HF:
# HF: Exception: data did not match any variant of untagged enum PyPreTokenizerTypeWrapper at line 78 column 3: xverse/XVERSE-7B-Chat
openchat/openchat_3.5
lmsys/vicuna-7b-v1.5
lmsys/longchat-7b-v1.5-32k