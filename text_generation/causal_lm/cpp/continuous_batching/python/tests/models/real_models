# Set of models with accuracy issues, because of PA
EleutherAI/pythia-160m
bigscience/bloomz-1b7
bigscience/bloomz-560m
databricks/dolly-v2-3b
tiiuae/falcon-rw-7b
bigcode/starcoder2-3b
openbmb/MiniCPM-2B-sft-bf16
openbmb/MiniCPM-2B-dpo-bf16
Qwen/Qwen-7B
Qwen/Qwen-7B-Chat
Qwen/Qwen1.5-0.5B
Qwen/Qwen1.5-7B-Chat
internlm/internlm-chat-7b
BAAI/Aquila-7B
internlm/internlm2-7b
openchat/openchat_3.5
lmsys/vicuna-7b-v1.5
lmsys/longchat-7b-v1.5-32k
BAAI/AquilaChat2-7B
BAAI/AquilaChat-7B
baichuan-inc/Baichuan-7B
tiiuae/falcon-7b
microsoft/Phi-3-mini-128k-instruct
microsoft/Phi-3-mini-4k-instruct
nomic-ai/gpt4all-mpt
mosaicml/mpt-7b
mosaicml/mpt-7b-chat
bigcode/starcoderbase-3b
bigcode/gpt_bigcode-santacoder
allenai/OLMo-1B-hf
allenai/OLMo-7B-hf
PygmalionAI/pygmalion-6b
stabilityai/stable-code-3b
berkeley-nest/Starling-LM-7B-alpha
EleutherAI/gpt-neo-2.7B
databricks/dolly-v1-6b
openai-community/gpt2-large
openai-community/gpt2-medium
bigscience/bloom-7b1
facebook/opt-1.3b
facebook/opt-2.7b
GAIR/Abel-7B-002
google/gemma-1.1-7b-it
google/gemma-2b-it
microsoft/DialoGPT-large
microsoft/DialoGPT-medium
Qwen/Qwen1.5-1.8B
microsoft/Orca-2-7b
# Set of models, failed because of C++ Cont. Batching
# RuntimeError: Check 'rt_info.find("eos_token_id") != rt_info.end(): facebook/incoder-1B
#
# Set of models, which require support in optimum-intel / transformers / models repositories:
# IndexError: tuple index out of range: facebook/blenderbot-3B
# `pip install flash_attn`: OrionStarAI/Orion-14B-Base
# ValueError: Trying to export a fuyu model, that is a custom or unsupported architecture: adept/fuyu-8b
# ValueError: Trying to export a mamba model, that is a custom or unsupported architecture: state-spaces/mamba-130m-hf
# ValueError: Trying to export a xlnet model, that is a custom or unsupported architecture: xlnet/xlnet-base-cased
#
# Set of models, failed because of CPU limitation
# head size must be multiple of 16, current: 100: pankajmathur/orca_mini_3b
# head size must be multiple of 16, current: 100: openlm-research/open_llama_3b
# head size must be multiple of 16, current: 100: openlm-research/open_llama_3b_v2
#
# Set of failed models, because of PA:
# 'start' input is not a scalar: google/pegasus-big_patent
# 'start' input is not a scalar: google/pegasus-large
# 'stop' input is not a scalar: Salesforce/codegen2-1b
# 'stop' input is not a scalar: core42/jais-13b
# 'stop' input is not a scalar: core42/jais-13b-chat
# Model references undeclared parameters: opset1::Parameter attention_mask () -> (i64[?,?]): facebook/opt-350m
#
# Set of models, failed because of OpenVINO Tokenizers:
# https://jira.devtools.intel.com/browse/CVS-142063: rinna/bilingual-gpt-neox-4b
# Cannot convert tokenizer of this type without `.model` file: deepseek-ai/deepseek-coder-33b-instruct
# Cannot convert tokenizer of this type without `.model` file: deepseek-ai/deepseek-coder-6.7b-instruct
# Tokenizer type is not supported: <class 'transformers.models.biogpt.tokenization_biogpt.BioGptTokenizer'>: microsoft/biogpt
#
# Set of 13B, 30B abd 70B models:
EleutherAI/gpt-neox-20b
mistralai/Mixtral-8x7B-v0.1
mistralai/Mixtral-8x7B-Instruct-v0.1
mosaicml/mpt-30b
# see optimum: OrionStarAI/Orion-14B-Base
# big model, not tried: OrionStarAI/Orion-14B-Chat
CohereForAI/c4ai-command-r-v01
openlm-research/open_llama_13b
Qwen/Qwen1.5-MoE-A2.7B
Qwen/Qwen1.5-MoE-A2.7B-Chat
xverse/XVERSE-MoE-A4.2B
cerebras/Cerebras-GPT-13B
WizardLMTeam/WizardCoder-15B-V1.0
TheBloke/Wizard-Vicuna-30B-Uncensored-GPTQ
#
# Set of passed models:
microsoft/phi-2
microsoft/phi-1_5
EleutherAI/gpt-neo-125m
EleutherAI/gpt-neo-1.3B
EleutherAI/gpt-j-6b
baichuan-inc/Baichuan2-7B-Chat
THUDM/chatglm2-6b
THUDM/chatglm3-6b
google/gemma-2b
google/gemma-7b
openai-community/gpt2
openai-community/gpt2-xl
gpt2
gpt2-xl
nomic-ai/gpt4all-j
stabilityai/stablelm-3b-4e1t
stabilityai/stablelm-2-zephyr-1_6b
meta-llama/Llama-2-7b-hf
meta-llama/Meta-Llama-3-8B-Instruct
meta-llama/CodeLlama-7b-hf
lmsys/vicuna-7b-v1.3
mistralai/Mistral-7B-v0.1
mistralai/Mistral-7B-Instruct-v0.1
01-ai/Yi-6B
Salesforce/codegen-350M-multi
Salesforce/codegen-350M-nl
togethercomputer/RedPajama-INCITE-Chat-3B-v1
# passed, but with export=False: OpenVINO/codegen25-7b-multi-fp16-ov
#
# Set of invalid models, because of HF:
# HF: Exception: data did not match any variant of untagged enum PyPreTokenizerTypeWrapper at line 78 column 3: xverse/XVERSE-7B-Chat
# https://huggingface.co/Salesforce/xgen-7b-8k-base/discussions/32: Salesforce/xgen-7b-8k-base