# Set of models with accuracy issues, because of PA:
EleutherAI/pythia-160m
bigscience/bloomz-1b7
bigscience/bloomz-560m
databricks/dolly-v2-3b
tiiuae/falcon-rw-7b
bigcode/starcoder2-3b
openbmb/MiniCPM-2B-sft-bf16
openbmb/MiniCPM-2B-dpo-bf16
Qwen/Qwen-7B
Qwen/Qwen-7B-Chat
Qwen/Qwen1.5-0.5B
Qwen/Qwen1.5-7B-Chat
rinna/bilingual-gpt-neox-4b
google/pegasus-big_patent
google/pegasus-large
#
# Set of models, which require support in optimum-intel:
# optimum-intel: Trying to export a RefinedWebModel model, that is a custom or unsupported architecture: nomic-ai/gpt4all-falcon
# optimum-intel: Trying to export a internlm model, that is a custom or unsupported architecture: internlm/internlm-chat-7b
# optimum-intel: Trying to export a mosaic-gpt model, that is a custom or unsupported architecture: mosaicml/mpt-1b-redpajama-200b
# optimum-intel: AttributeError: Could not find the attribute named "num_key_value_heads" in the normalized config: BAAI/Aquila-7B
# optimum-intel: PermissionError: [Errno 13] Permission denied: internlm/internlm2-7b
# optimum-intel: AttributeError: 'NoneType' object has no attribute 'device': Salesforce/codegen2-1b
# optimum-intel: TypeError: Object of type method is not JSON serializable: Salesforce/xgen-7b-8k-base
# optimum-intel: IndexError: tuple index out of range: facebook/blenderbot-3B
#
# Set of models, failed because of CPU limitation
# CPU: head size must be multiple of 16, current: 100: pankajmathur/orca_mini_3b
#
# Set of failed models, because of PA:
# Exception from src/core/src/shape_util.cpp:65: BAAI/AquilaChat2-7B
# Exception from src/core/src/shape_util.cpp:65: BAAI/AquilaChat-7B
# Exception from src/core/src/shape_util.cpp:65: baichuan-inc/Baichuan-7B
# Exception from src/core/src/shape_util.cpp:65: tiiuae/falcon-7b
# RuntimeError: Check 'unregistered_parameters.str().empty()': microsoft/Phi-3-mini-128k-instruct
# RuntimeError: Check 'unregistered_parameters.str().empty()': microsoft/Phi-3-mini-4k-instruct
# RuntimeError: Check 'unregistered_parameters.str().empty()': bigcode/starcoderbase-3b
# RuntimeError: Check 'unregistered_parameters.str().empty()': bigcode/gpt_bigcode-santacoder
# RuntimeError: Check 'unregistered_parameters.str().empty()': nomic-ai/gpt4all-mpt
# RuntimeError: Check 'unregistered_parameters.str().empty()': mosaicml/mpt-7b
# RuntimeError: Check 'unregistered_parameters.str().empty()': facebook/opt-350m
#
# Set of models, failed because of OpenVINO Tokenizers:
# RuntimeError: Check 'rt_info.find("eos_token_id") != rt_info.end(): facebook/incoder-1B
#
# Set of 13B, 30B abd 70B models:
# big model, not tried (Xeon): EleutherAI/gpt-neox-20b
# big model, not tried: core42/jais-13b
# big model, not tried (Xeon): core42/jais-13b-chat
# big model, not tried: young-geng/koala
# big model, not tried (Xeon): mistralai/Mixtral-8x7B-v0.1
# big model, not tried: mistralai/Mixtral-8x7B-Instruct-v0.1
# big model, not tried: mosaicml/mpt-30b
# big model, not tried (Xeon): OrionStarAI/Orion-14B-Base
# big model, not tried: OrionStarAI/Orion-14B-Chat
# big model, not tried: Qwen/Qwen1.5-MoE-A2.7B
# big model, not tried (Xeon): Qwen/Qwen1.5-MoE-A2.7B-Chat
# big model, not tried: xverse/XVERSE-MoE-A4.2B
#
# Set of passed models:
# passed: microsoft/phi-2
# passed: microsoft/phi-1_5
# passed: EleutherAI/gpt-neo-125m
# passed: EleutherAI/gpt-neo-125m
# passed: EleutherAI/gpt-neo-1.3B
# passed: EleutherAI/gpt-j-6b
# passed: baichuan-inc/Baichuan2-7B-Chat
# passed: THUDM/chatglm2-6b
# passed: THUDM/chatglm3-6b
# passed: google/gemma-2b
# passed: google/gemma-7b
# passed: openai-community/gpt2
# passed: openai-community/gpt2-xl
# passed: gpt2
# passed: gpt2-xl
# passed: nomic-ai/gpt4all-j
# passed: stabilityai/stablelm-3b-4e1t
# passed: stabilityai/stablelm-2-zephyr-1_6b
# passed: meta-llama/Llama-2-7b-hf
# passed: meta-llama/Meta-Llama-3-8B-Instruct
# passed: meta-llama/CodeLlama-7b-hf
# passed: lmsys/vicuna-7b-v1.3
# passed: openlm-research/open_llama_3b
# passed: openlm-research/open_llama_3b_v2
# passed: mistralai/Mistral-7B-v0.1
# passed: mistralai/Mistral-7B-Instruct-v0.1
# passed: allenai/OLMo-1B-hf
# passed: allenai/OLMo-7B-hf
# passed: 01-ai/Yi-6B
# passed: Salesforce/codegen-350M-multi
# passed: Salesforce/codegen-350M-nl
# passed: togethercomputer/RedPajama-INCITE-Chat-3B-v1
# passed, but with export=False: OpenVINO/codegen25-7b-multi-fp16-ov
#
# Set of invalid models, because of HF:
# HF: Exception: data did not match any variant of untagged enum PyPreTokenizerTypeWrapper at line 78 column 3: xverse/XVERSE-7B-Chat
# HF: DeciCoderAttention.forward() got an unexpected keyword argument 'cache_position': Deci/DeciCoder-1b
# HF: The generation config instance is invalid -- `.validate()` throws warnings and/or exceptions: openchat/openchat_3.5
# HF: The generation config instance is invalid -- `.validate(): lmsys/vicuna-7b-v1.5
# HF: The generation config instance is invalid -- `.validate(): lmsys/longchat-7b-v1.5-32k