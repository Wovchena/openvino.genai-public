import CodeExampleCPP from './_code_example_cpp.mdx';
import CodeExamplePython from './_code_example_python.mdx';

## Run Model Using OpenVINO GenAI

OpenVINO GenAI introduces the [`VLMPipeline`](https://docs.openvino.ai/2025/api/genai_api/_autosummary/openvino_genai.VLMPipeline.html) pipeline for inference of multimodal text-generation Vision Language Models (VLMs).
It can generate text from a text prompt and images as inputs.

<LanguageTabs>
    <TabItemPython>
        <Tabs groupId="device">
            <TabItem label="CPU" value="cpu">
                <CodeExamplePython device="CPU" />
            </TabItem>
            <TabItem label="GPU" value="gpu">
                <CodeExamplePython device="GPU" />
            </TabItem>
        </Tabs>
    </TabItemPython>
    <TabItemCpp>
        <Tabs groupId="device">
            <TabItem label="CPU" value="cpu">
                <CodeExampleCPP device="CPU" />
            </TabItem>
            <TabItem label="GPU" value="gpu">
                <CodeExampleCPP device="GPU" />
            </TabItem>
        </Tabs>
    </TabItemCpp>
</LanguageTabs>

The prompt can contain `<ov_genai_image_i>` with `i` replaced with an actual zero based index to refer to an image. Reference to images used in previous prompts isn't implemented. A model's native image tag can be used instead of `<ov_genai_image_i>`. These tags are:
1. InternVL2: `<image>\n`
2. llava-1.5-7b-hf: `<image>`
3. LLaVA-NeXT: `<image>`
4. MiniCPM-V-2_6: `(<image>./</image>)\n`
5. Phi-3-vision: `<|image_i|>\n` - the index starts with one
6. Qwen2-VL: `<|vision_start|><|image_pad|><|vision_end|>`

If the prompt doesn't contain image tags, but images are provided, the tags are prepended to the prompt.

:::tip

Use CPU or GPU as devices without any other code change.

:::
