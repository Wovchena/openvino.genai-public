name: llm-cpp
on:
  pull_request
jobs:
  llm-cpp:
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-20.04, ubuntu-22.04, windows-latest]
        python-version: [3.8, 3.9, '3.10', '3.11']
    runs-on: ${{ matrix.os }}
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: recursive
      - uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
      - run: |
          curl https://storage.openvinotoolkit.org/repositories/openvino/packages/nightly/2023.3.0-13432-a6ea22ad0e6/l_openvino_toolkit_ubuntu20_2023.3.0.dev20231129_x86_64.tgz | tar --directory ./ov/ --strip-components 1 -xz
          sudo ./ov/install_dependencies/install_openvino_dependencies.sh
          source ./ov/setupvars.sh
          python -m pip install --upgrade-strategy eager "transformers>=4.36" "optimum[openvino]>=1.15" --extra-index-url https://download.pytorch.org/whl/cpu
          python -m pip uninstall --yes optimum-intel
          python -m pip install git+https://github.com/huggingface/optimum-intel.git@5dac93d6e8d15c96fe061c653d82b7afd54954db
          optimum-cli export openvino -m TinyLlama/TinyLlama-1.1B-Chat-v0.6 .
